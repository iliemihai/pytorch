{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Invatare seq2seq cu retele neurale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In aceasta serie vom construi un model de machine learning care va mapa o secventa de cuvinte la alta secventa de cuvinte, ceea ce in limbajul de specialitate se cheama seq2seq, folsind Pytorch si TorchText. Acest model il vom aplica pentru a traduce propozitii din romana in engleza, insa se poate aplica si pentru alte taskuri cum ar fi sumarizarea unor documente (se mapeaza o secventa mare de cuvinte la o secventa mica de cuvinte) sau agenti conversationali(chatbots care mapeaza o intrebare la un raspuns).\n",
    "\n",
    "In acest document vom incerca sa intelegem conceptele generale in implementarea unui model de seq2seq. Pentru a afla mai multe detalii va recomand sa cititi lucrarea https://arxiv.org/abs/1409.3215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cel mai folosit model *seq2seq* este cel de *encoder-decoder*. Traditional acestea folosesc *retele neurale recurente* drept *encoder* pentru a reprezenta o propozitie data input ca un vector. Putem viziona acest vector ca o reprezentare abstracta a propozitiei primite. Pornind de la aceasta reprezentare alte *retele neurale recurente* drept *decoder* vor primi ca input acest vector si vor invata sa genereze o propozitie primita drept rezultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/seq2seq2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginea de mai sus este un exemplu despre cum functioneaza acest model. Propozitia \"buna dimineata\" este primita ca input de catre *stratul embedding* al encoderului. Acest strat din encoder reprezinta cel mai de jos nivel al retelei recurente si invata o reprezentare vectoriala a tuturor cuvintelor din datasetul pe care antrenam reteaua. Pentru a marca inceputul si finalul unei propozitii vom folosi marcatorii (<sos>) si (<eos>) respectiv. Encoderul va primi cuvintele din propozitie pe rand. La fiecare pas de timp, encoderul va primi ca input reprezentarea vectoriala a cuvantului curent din propozitie (aceasta reprezentare este invatata de stratul de embedding din encoder) si starea curenta invatata de *reteaua recurenta*. Aceasta stare este o abstractizare a propozitiei invatata de retea. O putem numi drept *stare ascunsa*. Reteaua recurenta poate fi vazuta ca o functie ce depinde de reprezentarea vectoriala $e(x_t)$ a cuvintelor din propozitii si *starea ascunsa* $h_{t-1}$ a propozitiei invatate pana la pasul $t$:\n",
    "    $$h_t = \\text{EncoderRNN}(e(x_t), h_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a deveni putin mai specifici vom utiliza tipuri speciale de *retele recurente* cum ar fi *Long Short Term Memory* sau *Gated Recurrent Unit* pentru *RNN*.\n",
    "\n",
    "Definim $X = \\{x_1, x_2, ..., x_T\\}$, $x_1$ = $<sos>$, $x_2$ = $buna$, $x_3$ = $dimineata$,$...$. Starea ascunsa initiala $h_0$ poate fi initializata cu zero sau invatata ca parametru.\n",
    "\n",
    "La final dupa ce ultimul cuvant $x_T$=$<eos>$ a fost primit de catre catre *RNN*, starea ascunsa finala $h_T$ va fi o reprezentare vectoriala a intregii propozitii.\n",
    "\n",
    "Avand aceasta reprezentare putem trece la pasul urmator, in care vom genera propozitia \"good morning\", $Y = \\{y_1, y_2, ..., y_T\\}$, $y_1$ = $<sos>$, $y_2$ = $good$, $y_3$ = $morning$,$...$. Din nou, la fiecare pas de timp, *RNN* din decoder primeste ca input reprezentarea vectoriala  $d(y_t)$ a cuvantului curent din propozitie si starea curenta  $s_{t-1}$ invatata de *reteaua recurenta* la pasul *t*. Stareainitiala $s_0$ = $h_t$ este aceeasi cu cea primita de la encoder. Asadar similar ecuatiei encoderului avem:\n",
    "    $$s_t = \\text{DecoderRNN}(d(y_t), s_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru encoder si decoder vom folosi straturi de embedding diferite, deoarece vocabularele de cuvinte corespunzator fiecarei limbi sunt diferite. In decoder, pornind de la vectorul de context primit de la encoder trebuie sa generam un cuvant, asadar la fiecare pas, peste starea curenta $s_t$ se aplica un model liniar pentru a prezice care credem ca ar fi urmatorul cuvant in propozitie, $\\hat{y}_t$.\n",
    "\n",
    "$$\\hat{y}_t = f(s_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In decoder, cuvintele sunt generate unul dupa altul. Cand decoderul primeste $<sos>$ incepe sa genereze iar cand primeste $<eos>$ stie ca trebuie sa se opreasca. O data ce a generat o propozitie, $\\hat{Y} = \\{ \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_T \\}$ o compara cu propozitia pe care am dori defapt sa o obtinem, $Y = \\{ y_1, y_2, ..., y_T \\}$. Calculeaza diferenta dintre cele doua propozitii, iar aceasta difenta este trimisa prin *backpropagation* ca sa faca corecteze parametrii modelului pentru a forta modelul sa genereze ce propozitie vrem. Acest model de antrenare se cheama *teacher forcing*, mai multe detalii in cartea lui Bengio https://www.deeplearningbook.org/contents/rnn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesare date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vom folosi Pytorch si TorchText pentru modele si vom folosi spaCy pentru tokenizare text. Vom folosi modelul de la HuggingFace pentru demo tokenizare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import spacy\n",
    "import tokenizers\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In continuare vom crea un tokenizator, unul cu spacy si unul cu hugging face, si vom vedea care e mai rapid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (ByteLevelBPETokenizer,\n",
    "                            CharBPETokenizer,\n",
    "                            SentencePieceBPETokenizer,\n",
    "                            BertWordPieceTokenizer)\n",
    "\n",
    "tokenizer_en = BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\", lowercase=True)\n",
    "\n",
    "tokenizer_ro = BertWordPieceTokenizer(\"roberto_word_level-vocab.txt\",lowercase=True)\n",
    "\n",
    "output = tokenizer_en.encode(\"Hello boy How are you\")\n",
    "print(output.tokens)\n",
    "tokenize_ro(\"Salut baiatul ce mai faci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai departe vom crea functiile de tokenizator. Vor primi o propozitie ca string si vor returna o lista de cuvinte. De exemplu, pentru decoder este mai ok daca ordinea cuvintelor este inversata deoarece aceasta ar creste acuratetea modelelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    return tokenizer_en.encode(text).tokens[::-1]\n",
    "\n",
    "def tokenize_ro(text):\n",
    "    return tokenizer_ro.encode(text).tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasa *Field* din TorchText proceseaza datele de input si de output.\n",
    "Setam romana ca fiind SRC (sursa input) si engleza ca TRG(target output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_ro,\n",
    "           init_token = \"<sos>\",\n",
    "           eos_token = \"<eos>\",\n",
    "           lower = True)\n",
    "\n",
    "TRG  = Field(tokenize=tokenize_en,\n",
    "            init_token=\"<sos>\",\n",
    "            eos_token=\"<eos>\",\n",
    "            lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum luam dataseturile de antrenare, validare si testare. Acestea pot fi ce vrem noi, de la datasets pt chatboti pana la dataseturi de translatie.\n",
    "\n",
    "Datasetul pe care il vom folosi este "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_path = os.path.abspath(os.getcwd()) + \"/eng_ro_train.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "train_data, valid_data = train_test_split(df, test_size=0.1)\n",
    "train_data.to_csv(\"train.csv\", index=False)\n",
    "valid_data.to_csv(\"valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am creat un dataset de train si un dataset de validare, fiecare cu 2 coloane (engleza, romana) unde fiecare rand contine o propozitie in engleza si o propozitie in romana\n",
    "\n",
    "Acum vom tokeniza dataseturile in liste de cuvinte conform *Field* definit mai sus pentru fiecare limba: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.dataset.TabularDataset object at 0x7f3643439240>\n",
      "Cuvinte unice (ro): 6877\n",
      "Cuvinte unice (en): 4945\n"
     ]
    }
   ],
   "source": [
    "data_fields = [('Engleza', TRG), ('Romana', SRC)]\n",
    "\n",
    "train, val, test = TabularDataset.splits(path=\"./\", train=\"train.csv\",   validation=\"valid.csv\", test='test.csv', format=\"csv\", fields=data_fields)\n",
    "print(test)\n",
    "SRC.build_vocab(train, val)\n",
    "TRG.build_vocab(train, val)\n",
    "\n",
    "\n",
    "print(f\"Cuvinte unice (ro): {len(SRC.vocab)}\")\n",
    "print(f\"Cuvinte unice (en): {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimul pas consta in crearea iteratorilor. Acestia vor returna o secventa de propozitii pe care o va primi ca input sub forma de tensori mapata la o secventa pe care o va avea drept output tot sub forma de tensori. Acesti tensori cuprind defapt indicii cuvintelor din vocabular.\n",
    "\n",
    "Singurul lucru de are va trebui sa mai avem grija este ca lungimea propozitiilor sa fie fixa. Acest lucru se realizaza prin completarea cu un cuvant dummy numit [PAD]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructia modelului Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aceasta cuprinde defapt trei parti: constructia encoder, constructia decoder si la final constructia model seq2sea care sa le imbine pe amandoaua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in lucrarea de mai sus, encoderul contine 4 straturi de LSTM. Noi vom folosi doar 2 pentru rapiditate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, in continuare vom construi decoderul care va avea de asemnea doua straturi de LSTM uri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru partea finala vom implementa seq2seq ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antrenam modelul Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum ca aveam modelul construit putem incepe antrenarea...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializam weighturile modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6877, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4945, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=4945, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculam numarul de parametrii din model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelul are 12,919,633 de parametetrii\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Modelul are {count_parameters(model):,} de parametetrii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim optimizatorul, ceea ce in cazul nostru va fi ori SGD ori ADAM. Pentru mai multe detalii puteti verifica ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urmeaza sa definim functia de loss. Pentru negative log likelyhood merge foarte bine pe traduceri, in schimb pt generare de text merge destul de prost pentru ca invata cuvintele cu cea mai mare frecventa. Desigur aceasta depinde si de decoder care acum este greedy, iar daca il schimbam cu beam search va fi mai bun. Un exemplu bun ar fi sa schimbam functia de negative log liklyhood cu alta functie de loss. Ma gandeasc la retele recurente bayesiane pe viitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(8.9865)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.randn(128, 4945).float()\n",
    "target = torch.FloatTensor(128).uniform_(0, 120).long()\n",
    "print(target.shape)\n",
    "criterion(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum trebuie sa definim training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.Romana\n",
    "        trg = batch.Engleza\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facem si o functie de evaluare, desi nu avem test dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.Romana\n",
    "            trg = batch.Engleza\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aceasta este o functie care numara cat timp a trecut pentru o epoca de antrenare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si in sfarsit putem incepe sa antrenam  modelul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 35s\n",
      "\tTrain Loss: 4.814 | Train PPL: 123.243\n",
      "\t Val. Loss: 4.347 |  Val. PPL:  77.273\n",
      "Epoch: 02 | Time: 1m 34s\n",
      "\tTrain Loss: 4.281 | Train PPL:  72.347\n",
      "\t Val. Loss: 4.353 |  Val. PPL:  77.683\n",
      "Epoch: 03 | Time: 1m 38s\n",
      "\tTrain Loss: 4.182 | Train PPL:  65.487\n",
      "\t Val. Loss: 4.332 |  Val. PPL:  76.071\n",
      "Epoch: 04 | Time: 1m 39s\n",
      "\tTrain Loss: 4.090 | Train PPL:  59.763\n",
      "\t Val. Loss: 4.364 |  Val. PPL:  78.574\n",
      "Epoch: 05 | Time: 1m 37s\n",
      "\tTrain Loss: 3.993 | Train PPL:  54.214\n",
      "\t Val. Loss: 4.382 |  Val. PPL:  79.963\n",
      "Epoch: 06 | Time: 1m 41s\n",
      "\tTrain Loss: 3.917 | Train PPL:  50.233\n",
      "\t Val. Loss: 4.387 |  Val. PPL:  80.408\n",
      "Epoch: 07 | Time: 1m 40s\n",
      "\tTrain Loss: 3.870 | Train PPL:  47.950\n",
      "\t Val. Loss: 4.394 |  Val. PPL:  80.997\n",
      "Epoch: 08 | Time: 1m 43s\n",
      "\tTrain Loss: 3.815 | Train PPL:  45.377\n",
      "\t Val. Loss: 4.420 |  Val. PPL:  83.080\n",
      "Epoch: 09 | Time: 1m 38s\n",
      "\tTrain Loss: 3.743 | Train PPL:  42.243\n",
      "\t Val. Loss: 4.319 |  Val. PPL:  75.116\n",
      "Epoch: 10 | Time: 1m 42s\n",
      "\tTrain Loss: 3.644 | Train PPL:  38.247\n",
      "\t Val. Loss: 4.241 |  Val. PPL:  69.464\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'Engleza'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-458-b653d6df08ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tut1-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-430-bc3cfdcf730f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRomana\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/pytorch/learn_pytorch/tutorials/pytorch_seq2seq/.env/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/pytorch/learn_pytorch/tutorials/pytorch_seq2seq/.env/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/pytorch/learn_pytorch/tutorials/pytorch_seq2seq/.env/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'Engleza'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
